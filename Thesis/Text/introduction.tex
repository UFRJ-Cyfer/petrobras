\chapter{Introduction}

\section{Introduction}
The increasing demand for energy over the past decades created a surge of renewable sources, as opposed to the more traditional petroleum fuel. However, that still is an essential fuel for our society, so that several companies like Shell, Exxon, and Petrobras have extensive and complex networks for extracting and distributing different kinds of liquid fuel through pipelines. Brazil for instance has roughly $8.000$ kilometers ($km$) \cite{WorldFactbookCentral2016} of oil pipelines (both refined and crude) scattered throughout the country.

In order to maintain and prevent failure (which could be catastrophic) several tests, both destructive and non-destructive were developed, and amongst the latter, one that stands out is the Acoustic Emission (AE) test. It relies on the radiation of acoustic (physical) waves that occurs when a material undergoes irreversible changes both at a micro and macroscopic scale (Section \ref{sec:acousticEmission}). 

Those changes can come from the propagation of a crack, corrosion, or in other words, irreversible damage to the material structure. Therefore it should be possible to monitor and tell in real time how dangerous it is.

\section{Theory}

This section gives a brief revision of the theoretical topics this thesis extends upon. 

\subsection{Learning}

Learning is something all beings have experienced one way or another, it is intrinsic to our nature and an essential process to our evolution as a society. It can be defined as a acquisition of knowledge through interaction, be it with the outside world like books, people, or with one's own self.

Knowledge however, is a more abstract concept and can be interpreted in several different ways, for instance, both knowing how to sew a scarf and differentiating square from circle can be considered knowledge. The different between those is that in the latter, the knowledge is static, interacting with it means only identifying which is which. Knowing how to sew a scarf however, means attaining domain over the cloth's process of transformation, given a simple piece of cloth (input), one would always be able to transform it into a scarf.

The ability to learn a transformation process is something rather powerful because one can change properties of the output merely changing the input, instead of relearning the whole process again, for example, being taught how to sew using only blue cloth does not impede one to sew a red scarf, needed only to change the fabric one applies the process.

Trying to create a machine that is able to act like we (thinking entities) do has been an open challenge since the 1950s \cite{turingCOMPUTINGMACHINERYINTELLIGENCE1950} and motivated countless studies amongst several decades on the field of Machine Learning (ML).

It is important to note however that mathematical complexity is a central factor in ML. Separating squares from circles can be done using rather simple mathematical formulae, sewing a scarf not. One can even map all the hand movements and develop formulae that reign it, but the complexity would make computation unrewarding. The goal of ML is to create a simpler model capable of acquiring that complex knowledge through learning.

However, one problem is still unresolved, how to measure the learning process. One can find it learnt how to sew a scarf when it does not deforms when pulled, or when it satisfies someone else. Expanding on that latter concept, one can for instance, attribute a beauty scale for the scarf (suppose for simplicity that the scale goes from 1 to 10), and only consider that it learnt how to sew a scarf when it can reliably sew a scarf that receives a 10 from the beauty scale.

The creation of a measure capable of telling if learning is in fact happening is of utmost importance for the learning process. We can then extend the definition of learning to the acquisition of knowledge through interaction that, as a by-product, increases the performance measure associated with that knowledge. The contrary is also possible, instead of increasing a performance measure, one can decrease an error measure.

Learning from the ML point of view can be separated in 3 main classes, Supervised Learning (Section \ref{sec:sup_learning}), Unsupervised Learning (Section \ref{sec:unsup_learning}) and Reinforced Learning. All those have the same principles, they all have a model, performance measure and a task to perform. The main difference is how they receive and interpret the input data.


\subsection{Supervised Learning}\label{sec:sup_learning}

As an undergrad is taking a calculus course, he is given several examples and exercises. Examples are composed of simpler questions and the necessary procedures, after reading them and taking the more challenging exercises, he gives them to the teacher, which in turn proceeds to tell him what he did right or wrong. He is then given a score based on how many questions he had right (how many hit the "target"), this procedure is repeated until the undergrad is satisfied with his score.

That is a prime example of Supervised Learning, as it can be defined as a method to train the model by directly teaching it. This is achieved through the addition of "labels" or "targets". The procedure from a mathematical point of view (Figure \ref{fig:sup_learning}) is fairly straightforward, your input data $\textbf{x}$ is fed to a model that yields the output $\tilde{\textbf{y}}$. The output is compared to the target $\textbf{y}$ and a performance/loss score $L(\cdot)$ is calculated.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{sup_learning_schematic}
	\caption{Simplified Supervised Learning Schematic}
	\label{fig:sup_learning}
\end{figure}

\subsection{Unsupervised Learning}\label{sec:unsup_learning}

Contrary to the aforementioned Supervised Learning method, Unsupervised Learning does not have a well specified "target" and therefore the model now has a different purpose, to create some sort of structure based solely on the inputs and the relationships between them. Unsupervised Learning typically translates to clustering.

Clustering is the action of grouping together inputs that have some degree of similarity, for instance, trying to separate different animals by the number of legs they possess, or which environment they reside is a type of unsupervised clustering since it depends only on the characteristics of the input data. A good example of this approach is recommendation systems.


\section{Artificial Neural Networks} \label{sec:ann}

What mainly highlights our species is the seemingly unending capacity to learn and adapt. The organ responsible for such, the brain has been subjected to 

Over the years, several studies (?????) have been published on the brain and its composition although several things are still undiscovered or undetermined.

The brain is the most complex organ in the human body and hosts $10$ to $20$ billion neurons, its main component. These neurons (Figure \ref{fig:neurons}) are physically connected through its dendrites and axons, these connections are susceptible to electrical impulses called synapses, most neural cells send signals through the axons and receive them from the dendrites.

\begin{figure}[H]
	\centering
    \def\svgwidth{0.6\columnwidth}
	\input{brain_neuron.pdf_tex}
	\caption{Structure of a Typical Neuron. Taken from \cite{wikimediacommonsNeuron2006}}
	\label{fig:neurons}
\end{figure}


While these operations are well understood, the way millions of interconnected neurons work and cooperate is still undiscovered(???). The Artificial Neural Network (ANN) is a supervised learning model (as the name states) inspired by that complex structure of the interconnected neurons, mainly composed of \textit{Perceptrons}.

\section{Perceptron} \label{sec:perceptron}

The \textit{Perceptron} can be interpreted as mathematical model for the neuron (Figure \ref{fig:neurons_mod}), it receives an input vector ($\textbf{x}$) through the dendrites, modifies it and releases an output ($\textbf{y}$) down the axons. 


\begin{figure}[H]
	\centering
	\def\svgwidth{0.6\columnwidth}
	\input{images/brain_neuron_mod.pdf_tex}
	\caption{Structure of a Typical Neuron with Inputs and Outputs. Adapted from \cite{wikimediacommonsNeuron2006}.}
	\label{fig:neurons_mod}
\end{figure}

Where $x_{n}$ and $y_{m}$ are elements from the $n$ and $m$-dimensional input and output vectors ($\textbf{x}$ and $\textbf{y}$) respectively. Initially, this model was used as a binary classifier using the synapses as weights, $m = 1$ and the addition of a bias (b) element, which gives:

\begin{equation}
	y = f(\textbf{w}\textbf{x} + b) = sign(\textbf{w}\textbf{x} + b) =
	\begin{cases} 
		1, & \mbox{if } \textbf{w}\textbf{x} + \textbf{b} > 0 \\
		-1, & \mbox{if } \mbox{ otherwise} 
	\end{cases}
\end{equation}

Where $\textbf{w}$ is a $[1\ x\ n]$ vector of weights. This model can be interpreted as a line in the input space that can both be translated (relative to the origin) and rotated. That line acts as a boundary separating two regions, or in other words, classifying two different groups of data.

The \textit{Perceptron} Learning Algorithm (PLA) is rather simple, for 

However, the boundary is still a straight line, meaning that if the data is not linearly separable (vast majority of real cases) it is impossible to achieve zero classification error. It would be interesting then to create different sorts of non-linear boundaries, to achieve that, one can "smooth" the underlying function $f(\textbf{w}\textbf{x})$ using for example $tanh(\cdot)$, $arctan(\cdot)$, etc.

Also, this thesis is going to adopt a slightly different notation, $\textbf{w}\textbf{x} + b \rightarrow \textbf{w}\textbf{x}$ where $w_{0} = 0$ and $x_{0} = 1$ thus giving:

\begin{equation}
\textbf{y} = f(\textbf{w}\textbf{x} + b) = f(\textbf{w}\textbf{x}) \rightarrow \Phi(\textbf{w}\textbf{x})
\end{equation}

Where $\textbf{w}$ are the synapses (weights) and $\Phi(\cdot)$ is an arbitrary mapping (activation function). It is important to note that there is a certain "flow" of information from $\textbf{x}$ to $\textbf{y}$, there is no feedback in the \textit{Perceptron} model (Figure \ref{fig:perceptron}).

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{perceptron}
	\caption{Complete Perceptron Mathematical Model.}
	\label{fig:perceptron}
\end{figure}



\subsection{Multi Layer Perceptron}

\subsection{Backpropagation}

\section{Acoustic Emission}

