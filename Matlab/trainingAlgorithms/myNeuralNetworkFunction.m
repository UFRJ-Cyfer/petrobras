
% figure; plot(mean(abs(fft_vallen(1:9000,1:time_sp)),2))
% figure; plot(mean(abs(fft_vallen(1:9000,time_sp+1:time_pi)),2))
% figure; plot(mean(abs(fft_vallen(1:9000,time_pi:end)),2))
% 
% E = E';
% figure; plot(mean(abs(E(1:9000,1:time_sp)),2))
% figure; plot(mean(abs(E(1:9000,time_sp+1:time_pi)),2))
% figure; plot(mean(abs(E(1:9000,time_pi:end)),2))

C_neural_net = zeros(3,3,100)

for m=1:100

for neuron_size = 15:15

% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 29-Apr-2017 20:56:19
%
% This script assumes these variables are defined:
%
%   E_entry - input data.
%   output_classes - target data.
% x = E_entry';
% t = (output_classes)';

x = E_entry(1:end,:)';
t = y_classes(:,1:end);
% 
% [trainInd,valInd,testInd] = dividerand(size(x,2),0.8,0.0,0.2);
% 
% x_train = x(:,trainInd);
% % x_val = x(:,valInd);
% x_test = x(:,testInd);
% 
% t_train = t(:,trainInd);
% 
% x_train = [x_train x(:,trainInd(trainInd >time_sp & trainInd < time_pi))];
% x_train = [x_train x(:,trainInd(trainInd > time_pi))];
% 
% t_train = [t_train t(:,trainInd(trainInd >time_sp & trainInd < time_pi))];
% t_train = [t_train t(:,trainInd(trainInd > time_pi))];




% x = E_entry';
% t = (output_classes)';

% E_Entry = [E_entry; E_entry(1450:end,:)];
% output_C = [output_classes; output_classes(1450:end,:)];

% x = E_Entry';
% t = (output_C)';

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainbr';  % Scaled conjugate gradient backpropagation.

% Create a Pattern Recognition Network
hiddenLayerSize = neuron_size;
net = patternnet([hiddenLayerSize hiddenLayerSize]);
%net.layers{2}.transferFcn = 'tansig';
net.trainFcn = trainFcn;
%net.layers{3}.transferFcn = 'tansig';

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
 net.input.processFcns = {'removeconstantrows','mapminmax'};
% net.output.processFcns = {'removeconstantrows','mapminmax'};

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivide
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 65/100;
net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 20/100;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'crossentropy';  % Cross-Entropy

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotconfusion', 'plotroc'};

net.trainParam.min_grad = 1e-16;
net.trainParam.max_fail = 10;
net.trainParam.lr = 0.1;
net.trainParam.showWindow = 0;

% Train the Network
% [net,tr] = train(net,x_train,t_train,'useGPU','yes');

%  [net,tr] = train(net,x,t,'useGPU','yes');
 [net,tr] = train(net,x,t);


% Test the Network
% y = net(x_test);
 y = net(x);

%figure;
% plot(y_,'r.');
% xlabel('Índice da entrada')
% legend('Saída da Rede','Location','northoutside','Orientation','horizontal')
% legend('boxoff')
% grid on;
% hold on


[y_max, i_max] =  max(y);
aux = [1; 2; 3];
y_filtered = [];

for k=1:size(i_max,2)
  y_filtered(:,k) = 1*(aux==i_max(k));
end
% 
% figure;
% y_filtered_rgb = reshape(y_filtered',1,size(i_max,2),3);
% t_rgb = reshape(t',1,size(i_max,2),3);
% imagesc(t_rgb)
% 
% y_rgb = reshape(y',1,size(i_max,2),3);
% figure
% imagesc(y)
% figure
% subplot(2,1,2)
% test_indexes = ~isnan(tr.testMask{1});
% imagesc(y_filtered_rgb(:,test_indexes(1,:),:))
% 
% subplot(2,1,1)
% imagesc(t_rgb(:,test_indexes(1,:),:))



% figure(6);
% title('Referência')
% colormap(eye(3))
% hold on
% L = line(ones(3),ones(3), 'LineWidth',2);               % generate line 
% set(L,{'color'},mat2cell(eye(3),ones(1,3),3));            % set the colors according to cmap
% legend('SP','PE','PI')
% 
% figure(4)
% title('Saída da Rede')
% xlabel('Índice da entrada')

% 
% plot(y(i_max,:))
% plot(i_max,'.')
% hold on;
% plot(t);
% plot(zeros(size(t)),'k--')


% e = gsubtract(t,y);
% performance = perform(net,t,y)
% tind = vec2ind(t);
% yind = vec2ind(y);
% percentErrors = sum(tind ~= yind)/numel(tind);

% Recalculate Training, Validation and Test Performance
% trainTargets = t .* tr.trainMask{1};
% valTargets = t .* tr.valMask{1};
testTargets = t .* tr.testMask{1};

% testTargets = t(:,testInd);

y_filtered_conf = y_filtered;


for k=1:3
    testTargets(k,:) = k*testTargets(k,:);
    y_filtered_conf(k,:) = k*y_filtered_conf(k,:);
end


testTargets = sum(testTargets,1);
y_filtered_conf = sum(y_filtered_conf,1);

C = confusionmat(testTargets,y_filtered_conf)
C(1,:) = C(1,:)/sum(C(1,:));
C(2,:) = C(2,:)/sum(C(2,:));
C(3,:) = C(3,:)/sum(C(3,:));
 C
 
 C_neural_net(:,:,m) = C;
 
end


 
end
mean_C = mean(C_neural_net,3)
std_C = std(C_neural_net,0,3)

